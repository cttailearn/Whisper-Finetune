import whisper
import gradio as gr
import os
import tempfile
import warnings
from whisper.tokenizer import LANGUAGES
import subprocess
import threading
import time
import logging
from pathlib import Path
import json
import pandas as pd
import traceback
import random
import soundfile
from tqdm import tqdm
from modelscope.pipelines import pipeline
from modelscope.utils.constant import Tasks
import argparse
import functools
import gc
import platform
import numpy as np
import torch
from torch.utils.data import DataLoader
from transformers import WhisperForConditionalGeneration, WhisperProcessor, WhisperFeatureExtractor, WhisperTokenizerFast, AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline
from peft import PeftModel, PeftConfig
import re
import shutil
import psutil  # æ–°å¢ç”¨äºç£ç›˜ç©ºé—´æ£€æŸ¥
import signal

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# å¿½ç•¥ä¸å¿…è¦çš„è­¦å‘Š
warnings.filterwarnings("ignore")

# è®¾ç½®ä¸´æ—¶ç›®å½•å’Œç¼“å­˜ç›®å½•
temp_dir = tempfile.mkdtemp()
os.environ['GRADIO_TEMP_DIR'] = temp_dir
os.environ['GRADIO_CACHE_DIR'] = os.path.join(temp_dir, 'gradio_cache')

# æ¨¡å‹ç¼“å­˜å­—å…¸ï¼Œé¿å…é‡å¤åŠ è½½æ¨¡å‹
model_cache = {}

# è®­ç»ƒçŠ¶æ€
TRAINING_PROCESS = None
TRAINING_THREAD = None
OUTPUT_FILE = None
TRAINING_ACTIVE = False

# ============================== æ­¥éª¤1: æ•°æ®å‡†å¤‡åŠŸèƒ½ ==============================
def data_prep_get_columns(input_file):
    """è·å–æ–‡ä»¶çš„åˆ—å"""
    if input_file is None:
        return []
    try:
        if input_file.endswith('.csv'):
            df = pd.read_csv(input_file, nrows=0)
        elif input_file.endswith('.xls'):
            df = pd.read_excel(input_file, engine='xlrd', nrows=0)
        else:
            df = pd.read_excel(input_file, engine='openpyxl', nrows=0)
        return df.columns.tolist()
    except Exception as e:
        print(f"Error reading file: {e}")
        traceback.print_exc()
        return []

def check_disk_space(path, required_mb=100):
    """æ£€æŸ¥ç£ç›˜ç©ºé—´æ˜¯å¦è¶³å¤Ÿ"""
    try:
        if platform.system() == 'Windows':
            free_bytes = psutil.disk_usage(path).free
        else:
            stat = os.statvfs(path)
            free_bytes = stat.f_frsize * stat.f_bavail
        
        free_mb = free_bytes / (1024 * 1024)
        return free_mb > required_mb
    except Exception as e:
        print(f"æ— æ³•æ£€æŸ¥ç£ç›˜ç©ºé—´: {str(e)}")
        return True  # å¦‚æœæ— æ³•æ£€æŸ¥ï¼Œå‡è®¾ç©ºé—´è¶³å¤Ÿ

def save_dataset(results, output_dir, enable_split, train_ratio):
    """ä¿å­˜æ•°æ®é›†åˆ°æ–‡ä»¶ï¼ˆå¢å¼ºé”™è¯¯å¤„ç†ï¼‰"""
    try:
        # æ£€æŸ¥è¾“å‡ºç›®å½•æ˜¯å¦å­˜åœ¨ä¸”å¯å†™
        if not os.path.exists(output_dir):
            os.makedirs(output_dir, exist_ok=True)
        
        if not os.access(output_dir, os.W_OK):
            return None, f"é”™è¯¯ï¼šç›®å½• {output_dir} ä¸å¯å†™ï¼"
        
        # æ£€æŸ¥ç£ç›˜ç©ºé—´ï¼ˆè‡³å°‘éœ€è¦100MBï¼‰
        if not check_disk_space(output_dir, 100):
            return None, f"é”™è¯¯ï¼šç£ç›˜ç©ºé—´ä¸è¶³ï¼ˆéœ€è¦è‡³å°‘100MBï¼‰ï¼"
        
        # ç©ºæ•°æ®é›†æ£€æŸ¥
        if not results:
            return None, "è­¦å‘Šï¼šå¤„ç†åçš„æ•°æ®é›†ä¸ºç©ºï¼Œè·³è¿‡æ–‡ä»¶ç”Ÿæˆï¼"
        
        # æ–‡ä»¶ä¿å­˜é€»è¾‘
        if enable_split:
            # éšæœºæ‰“ä¹±æ•°æ®
            random.shuffle(results)
            
            # è®¡ç®—åˆ’åˆ†ç‚¹
            total_count = len(results)
            train_count = int(total_count * train_ratio)
            
            # åˆ’åˆ†æ•°æ®
            train_data = results[:train_count]
            test_data = results[train_count:]
            
            # ç”Ÿæˆæ–‡ä»¶åï¼ˆå¸¦æ—¶é—´æˆ³é¿å…è¦†ç›–ï¼‰
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            train_file = os.path.join(output_dir, f"train_{timestamp}.jsonl")
            test_file = os.path.join(output_dir, f"test_{timestamp}.jsonl")
            info_file = os.path.join(output_dir, f"dataset_info_{timestamp}.txt")
            
            output_files = [train_file, test_file, info_file]
            
            # ä¿å­˜è®­ç»ƒé›†ï¼ˆåˆ†æ‰¹å†™å…¥ï¼‰
            try:
                with open(train_file, 'w', encoding='utf-8') as f:
                    for i in range(0, len(train_data), 10000):
                        chunk = train_data[i:i+10000]
                        for item in chunk:
                            f.write(json.dumps(item, ensure_ascii=False) + '\n')
                print(f"è®­ç»ƒé›†ä¿å­˜æˆåŠŸ: {train_file}")
            except IOError as e:
                return None, f"å†™å…¥è®­ç»ƒé›†å¤±è´¥: {str(e)}"
            
            # ä¿å­˜æµ‹è¯•é›†ï¼ˆåˆ†æ‰¹å†™å…¥ï¼‰
            try:
                with open(test_file, 'w', encoding='utf-8') as f:
                    for i in range(0, len(test_data), 10000):
                        chunk = test_data[i:i+10000]
                        for item in chunk:
                            f.write(json.dumps(item, ensure_ascii=False) + '\n')
                print(f"æµ‹è¯•é›†ä¿å­˜æˆåŠŸ: {test_file}")
            except IOError as e:
                return None, f"å†™å…¥æµ‹è¯•é›†å¤±è´¥: {str(e)}"
            
            # åˆ›å»ºæ•°æ®é›†ä¿¡æ¯
            try:
                with open(info_file, 'w', encoding='utf-8') as f:
                    f.write(f"æ•°æ®é›†åˆ’åˆ†ä¿¡æ¯\n")
                    f.write(f"ç”Ÿæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
                    f.write(f"æ€»æ•°æ®é‡: {total_count}\n")
                    f.write(f"è®­ç»ƒé›†: {len(train_data)} ({train_ratio*100:.1f}%)\n")
                    f.write(f"æµ‹è¯•é›†: {len(test_data)} ({(1-train_ratio)*100:.1f}%)\n")
                    f.write(f"è®­ç»ƒé›†æ–‡ä»¶: {train_file}\n")
                    f.write(f"æµ‹è¯•é›†æ–‡ä»¶: {test_file}\n")
                print(f"æ•°æ®é›†ä¿¡æ¯ä¿å­˜æˆåŠŸ: {info_file}")
            except IOError as e:
                return None, f"å†™å…¥æ•°æ®é›†ä¿¡æ¯å¤±è´¥: {str(e)}"
            
            return output_files, f"æ•°æ®é›†å·²ç”Ÿæˆ: {len(output_files)}ä¸ªæ–‡ä»¶"
        else:
            # ç”Ÿæˆæ–‡ä»¶åï¼ˆå¸¦æ—¶é—´æˆ³é¿å…è¦†ç›–ï¼‰
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            output_file = os.path.join(output_dir, f"whisper_data_{timestamp}.json")
            
            # åˆ†æ‰¹å†™å…¥å¤§å‹æ•°æ®é›†
            try:
                with open(output_file, 'w', encoding='utf-8') as f:
                    for i in range(0, len(results), 10000):
                        chunk = results[i:i+10000]
                        for item in chunk:
                            f.write(json.dumps(item, ensure_ascii=False) + '\n')
                print(f"æ•°æ®é›†ä¿å­˜æˆåŠŸ: {output_file}")
                return [output_file], f"æ•°æ®é›†å·²ç”Ÿæˆ: {output_file}"
            except IOError as e:
                return None, f"å†™å…¥æ•°æ®é›†å¤±è´¥: {str(e)}"
    
    except Exception as e:
        traceback.print_exc()
        return None, f"ä¿å­˜è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}"

def data_prep_generate_json(input_file, audio_col, text_col, language_col, 
                 start_col, end_col, segment_text_col, output_dir, include_sentences, 
                 include_duration, train_ratio, enable_split, add_punctuation, auto_calc_duration):
    """ç”ŸæˆJSONæ–‡ä»¶çš„ä¸»å‡½æ•°ï¼ˆä¿®å¤æ–‡ä»¶ç”Ÿæˆé—®é¢˜ï¼‰"""
    try:
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(output_dir, exist_ok=True)
        
        # è¯»å–è¾“å…¥æ–‡ä»¶
        if input_file.endswith('.csv'):
            df = pd.read_csv(input_file)
        elif input_file.endswith('.xls'):
            df = pd.read_excel(input_file, engine='xlrd')
        else:
            df = pd.read_excel(input_file, engine='openpyxl')
        
        # åˆå§‹åŒ–ç»“æœåˆ—è¡¨
        results = []
        total_rows = len(df)
        processed_count = 0
        error_count = 0
        
        # åˆå§‹åŒ–æ ‡ç‚¹æ¨¡å‹ï¼ˆå¦‚æœéœ€è¦ï¼‰
        pun_model = None
        if add_punctuation:
            try:
                pun_model = pipeline(
                    task=Tasks.punctuation,
                    model='iic/punc_ct-transformer_cn-en-common-vocab471067-large',
                    model_revision="v2.0.4"
                )
                print("æ ‡ç‚¹æ¢å¤æ¨¡å‹åŠ è½½æˆåŠŸ")
            except Exception as e:
                print(f"åŠ è½½æ ‡ç‚¹æ¢å¤æ¨¡å‹å¤±è´¥: {e}")
                add_punctuation = False
        
        # å¤„ç†æ¯ä¸€è¡Œæ•°æ®
        for index, row in tqdm(df.iterrows(), total=len(df), desc="å¤„ç†æ•°æ®"):
            try:
                # åŸºç¡€å­—æ®µå¤„ç†
                audio_path = row[audio_col] if audio_col != "ä¸é€‰æ‹©" else f"audio_{index}.wav"
                sentence = row[text_col] if text_col != "ä¸é€‰æ‹©" else ""
                
                # åº”ç”¨æ ‡ç‚¹æ¢å¤ - ä¿®å¤: ä½¿ç”¨æ­£ç¡®çš„è¾“å…¥æ ¼å¼
                if add_punctuation and sentence:
                    try:
                        # ä¿®å¤: ä¼ é€’å­—å…¸æ ¼å¼è€Œä¸æ˜¯å­—ç¬¦ä¸²
                        result = pun_model({'text': sentence})
                        if isinstance(result, dict) and 'text' in result:
                            sentence = result['text']
                        else:
                            print(f"æ ‡ç‚¹æ¢å¤è¿”å›æ„å¤–æ ¼å¼: {type(result)}")
                    except Exception as e:
                        print(f"æ ‡ç‚¹æ¢å¤å¤±è´¥: {e}")
                
                # è¯­è¨€å¤„ç†
                language = row[language_col] if language_col != "ä¸é€‰æ‹©" else "Chinese"
                
                # æ„å»ºåŸºç¡€JSONç»“æ„
                result = {
                    "audio": {
                        "path": str(audio_path)
                    },
                    "sentence": str(sentence),
                    "language": str(language)
                }
                
                # è‡ªåŠ¨è®¡ç®—éŸ³é¢‘æ—¶é•¿ï¼ˆä½¿ç”¨é«˜æ•ˆæ–¹æ³•ï¼‰
                duration = 0.6
                if auto_calc_duration:
                    try:
                        # ä½¿ç”¨soundfileçš„SoundFileä¸Šä¸‹æ–‡ç®¡ç†å™¨é«˜æ•ˆè·å–æ—¶é•¿
                        with soundfile.SoundFile(audio_path) as f:
                            duration = round(len(f) / f.samplerate, 2)
                    except Exception as e:
                        print(f"è®¡ç®—éŸ³é¢‘æ—¶é•¿å¤±è´¥: {e}")
                
                # åˆ†æ®µä¿¡æ¯å¤„ç†
                has_segment_data = (start_col != "ä¸é€‰æ‹©" and end_col != "ä¸é€‰æ‹©" and segment_text_col != "ä¸é€‰æ‹©")
                
                if include_sentences:
                    sentences_list = []
                    
                    if has_segment_data:
                        # å¤„ç†åˆ†æ®µæ•°æ®
                        starts = data_prep_parse_segment_data(row[start_col])
                        ends = data_prep_parse_segment_data(row[end_col])
                        texts = data_prep_parse_segment_data(row[segment_text_col], is_text=True)
                        
                        # åº”ç”¨æ ‡ç‚¹æ¢å¤åˆ°åˆ†æ®µæ–‡æœ¬ - ä¿®å¤: ä½¿ç”¨æ­£ç¡®çš„è¾“å…¥æ ¼å¼
                        if add_punctuation:
                            processed_texts = []
                            for t in texts:
                                try:
                                    # ä¿®å¤: ä¼ é€’å­—å…¸æ ¼å¼è€Œä¸æ˜¯å­—ç¬¦ä¸²
                                    result = pun_model({'text': t})
                                    if isinstance(result, dict) and 'text' in result:
                                        processed_texts.append(result['text'])
                                    else:
                                        processed_texts.append(t)
                                        print(f"æ ‡ç‚¹æ¢å¤è¿”å›æ„å¤–æ ¼å¼: {type(result)}")
                                except Exception as e:
                                    print(f"åˆ†æ®µæ ‡ç‚¹æ¢å¤å¤±è´¥: {e}")
                                    processed_texts.append(t)
                            texts = processed_texts
                        
                        # åˆ›å»ºåˆ†æ®µåˆ—è¡¨
                        for s, e, t in zip(starts, ends, texts):
                            sentences_list.append({
                                "start": float(s),
                                "end": float(e),
                                "text": t
                            })
                        
                        # å¦‚æœåŒæ—¶éœ€è¦durationå­—æ®µï¼Œä½¿ç”¨æœ€åä¸€ä¸ªç»“æŸæ—¶é—´
                        if include_duration and ends:
                            duration = ends[-1]
                    else:
                        # æ²¡æœ‰åˆ†æ®µæ•°æ®ä½†ç”¨æˆ·è¦æ±‚åŒ…å«sentenceså­—æ®µ
                        sentences_list.append({
                            "start": 0.0,
                            "end": duration if auto_calc_duration and duration > 0 else 0.0,
                            "text": sentence
                        })
                    
                    result["sentences"] = sentences_list
                
                # å¤„ç†durationå­—æ®µ
                if include_duration:
                    if has_segment_data and not include_sentences:
                        ends = data_prep_parse_segment_data(row[end_col])
                        duration = ends[-1] if ends else 0.0
                    result["duration"] = float(duration) if duration > 0 else 0.0
                
                results.append(result)
                processed_count += 1
            except Exception as e:
                print(f"Error processing row {index}: {e}")
                traceback.print_exc()
                error_count += 1
        
        # è°ƒç”¨å¢å¼ºç‰ˆä¿å­˜å‡½æ•°
        saved_files, save_message = save_dataset(
            results, 
            output_dir, 
            enable_split, 
            train_ratio
        )
        
        if saved_files:
            # æ·»åŠ æ–‡ä»¶å¤§å°ä¿¡æ¯
            file_info = []
            for file in saved_files:
                try:
                    size_mb = os.path.getsize(file) / (1024 * 1024)
                    file_info.append(f"{os.path.basename(file)}: {size_mb:.2f}MB")
                except:
                    file_info.append(f"{os.path.basename(file)}: å¤§å°æœªçŸ¥")
            
            summary = [
                f"âœ… æ•°æ®é›†ç”ŸæˆæˆåŠŸï¼",
                f"æ€»è¡Œæ•°: {total_rows}",
                f"æˆåŠŸå¤„ç†: {processed_count}",
                f"å¤±è´¥è¡Œæ•°: {error_count}",
                f"ä¿å­˜æ–‡ä»¶:"
            ] + file_info
            
            return "\n".join(summary)
        else:
            return save_message
    except Exception as e:
        print(f"Error generating JSON: {e}")
        traceback.print_exc()
        return f"ç”Ÿæˆå¤±è´¥: {str(e)}"

def data_prep_parse_segment_data(data, is_text=False):
    """è§£æåˆ†æ®µæ•°æ®ï¼Œæ”¯æŒå¤šç§æ ¼å¼"""
    if pd.isna(data):
        return []
    
    if isinstance(data, list):
        return data
    elif isinstance(data, str):
        # å°è¯•å¤šç§åˆ†éš”ç¬¦
        if ";" in data:
            return data.split(";")
        elif "|" in data:
            return data.split("|")
        elif "," in data:
            return data.split(",")
        elif "\n" in data:
            return data.split("\n")
        else:
            return [data]
    else:
        return [str(data)]

def data_prep_update_preview(input_file):
    """æ›´æ–°æ•°æ®é¢„è§ˆ"""
    if not input_file:
        return pd.DataFrame(), ["ä¸é€‰æ‹©"]
    
    try:
        if input_file.endswith('.csv'):
            df = pd.read_csv(input_file)
        elif input_file.endswith('.xls'):
            df = pd.read_excel(input_file, engine='xlrd')
        else:
            df = pd.read_excel(input_file, engine='openpyxl')
        
        preview = df.head(5)
        columns = df.columns.tolist()
        options = ["ä¸é€‰æ‹©"] + columns
        return preview, options
    except Exception as e:
        print(f"Error updating preview: {e}")
        traceback.print_exc()
        return pd.DataFrame(), ["ä¸é€‰æ‹©"]

# ============================== æ­¥éª¤2: æ¨¡å‹è®­ç»ƒåŠŸèƒ½ ==============================
def load_model(model_name_or_path, download_root=None, is_local_model=False):
    """åŠ è½½æ¨¡å‹ï¼Œæ”¯æŒé¢„å®šä¹‰æ¨¡å‹åç§°æˆ–æœ¬åœ°è·¯å¾„"""
    # å¦‚æœæœªæŒ‡å®šä¸‹è½½ç›®å½•ï¼Œä½¿ç”¨å½“å‰å·¥ä½œç›®å½•
    if download_root is None or download_root.strip() == "":
        download_root = os.getcwd()  # é»˜è®¤ä¸‹è½½åˆ°å½“å‰ç›®å½•
    
    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²åŠ è½½
    cache_key = f"{model_name_or_path}_{download_root}_{is_local_model}"
    if cache_key in model_cache:
        print(f"ä½¿ç”¨ç¼“å­˜çš„æ¨¡å‹: {cache_key}")
        return model_cache[cache_key]
    
    try:
        if is_local_model:
            # æœ¬åœ°æ¨¡å‹è·¯å¾„å¤„ç†
            model_path = model_name_or_path.strip()
            
            # æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
            if not os.path.exists(model_path):
                raise FileNotFoundError(f"æœ¬åœ°æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}")
            
            print(f"åŠ è½½æœ¬åœ°æ¨¡å‹: {model_path}")
            
            # å°è¯•ä¸åŒçš„åŠ è½½æ–¹å¼
            try:
                # æ–¹æ³•1: å°è¯•ä½¿ç”¨transformersåº“åŠ è½½ï¼ˆæ”¯æŒHugging Faceæ ¼å¼ï¼‰
                from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor
                print("å°è¯•ä½¿ç”¨transformersåº“åŠ è½½æ¨¡å‹...")
                
                # è®¾ç½®è®¾å¤‡å’Œæ•°æ®ç±»å‹
                device = "cuda:0" if torch.cuda.is_available() else "cpu"
                torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32
                
                # åŠ è½½å¤„ç†å™¨å’Œæ¨¡å‹
                processor = AutoProcessor.from_pretrained(model_path, local_files_only=True)
                model = AutoModelForSpeechSeq2Seq.from_pretrained(
                    model_path, 
                    torch_dtype=torch_dtype, 
                    low_cpu_mem_usage=True, 
                    use_safetensors=True,
                    local_files_only=True
                )
                model.generation_config.forced_decoder_ids = None
                model.to(device)
                
                # åˆ›å»ºæ¨ç†ç®¡é“
                from transformers import pipeline
                pipe = pipeline(
                    "automatic-speech-recognition",
                    model=model,
                    tokenizer=processor.tokenizer,
                    feature_extractor=processor.feature_extractor,
                    chunk_length_s=30,
                    batch_size=16,
                    torch_dtype=torch_dtype,
                    device=device
                )
                
                print("ä½¿ç”¨transformersåº“åŠ è½½æˆåŠŸ")
                # è¿”å›åŒ…è£…åçš„æ¨¡å‹å¯¹è±¡ï¼Œå…¼å®¹åŸæœ‰æ¥å£
                class TransformersWhisperModel:
                    def __init__(self, pipe, processor):
                        self.pipe = pipe
                        self.processor = processor
                        self.device = device
                    
                    def transcribe(self, audio, language=None, task="transcribe", **kwargs):
                        """å…¼å®¹whisper.load_modelçš„transcribeæ¥å£"""
                        generate_kwargs = {"task": task}
                        if language:
                            generate_kwargs["language"] = language
                        
                        result = self.pipe(audio, return_timestamps=True, generate_kwargs=generate_kwargs)
                        return result
                
                wrapped_model = TransformersWhisperModel(pipe, processor)
                model_cache[cache_key] = wrapped_model
                return wrapped_model
                
            except Exception as e1:
                print(f"transformersåº“åŠ è½½å¤±è´¥: {e1}")
                
                # æ–¹æ³•2: å°è¯•ç›´æ¥ä½¿ç”¨whisper.load_modelåŠ è½½
                try:
                    print("å°è¯•ä½¿ç”¨whisper.load_modelåŠ è½½...")
                    
                    # å¦‚æœæ˜¯ç›®å½•ï¼ŒæŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶
                    if os.path.isdir(model_path):
                        # æŸ¥æ‰¾å¸¸è§çš„æ¨¡å‹æ–‡ä»¶
                        possible_files = [
                            os.path.join(model_path, "pytorch_model.bin"),
                            os.path.join(model_path, "model.pt"),
                            os.path.join(model_path, "whisper.pt"),
                            os.path.join(model_path, "model.pth"),
                            os.path.join(model_path, "model.safetensors")
                        ]
                        
                        model_file = None
                        for file_path in possible_files:
                            if os.path.exists(file_path):
                                model_file = file_path
                                break
                        
                        if model_file is None:
                            # å¦‚æœæ²¡æ‰¾åˆ°æ ‡å‡†æ–‡ä»¶ï¼Œåˆ—å‡ºç›®å½•ä¸­çš„æ‰€æœ‰.ptå’Œ.binæ–‡ä»¶
                            pt_files = [f for f in os.listdir(model_path) if f.endswith(('.pt', '.bin', '.pth'))]
                            if pt_files:
                                model_file = os.path.join(model_path, pt_files[0])
                                print(f"æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {model_file}")
                            else:
                                # åˆ—å‡ºç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶ï¼Œå¸®åŠ©ç”¨æˆ·è°ƒè¯•
                                all_files = os.listdir(model_path)
                                raise FileNotFoundError(
                                    f"åœ¨ç›®å½• {model_path} ä¸­æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶ (.pt, .bin, .pth, .safetensors)ã€‚\n"
                                    f"ç›®å½•ä¸­çš„æ–‡ä»¶: {', '.join(all_files[:10])}{'...' if len(all_files) > 10 else ''}\n"
                                    f"è¯·ç¡®ä¿ç›®å½•ä¸­åŒ…å«ä»¥ä¸‹æ ¼å¼ä¹‹ä¸€çš„æ¨¡å‹æ–‡ä»¶ï¼špytorch_model.bin, model.pt, whisper.pt, model.pth, model.safetensors"
                                )
                        
                        model_path = model_file

                    if model_path.endswith('.safetensors'):
                        print("æ£€æµ‹åˆ°.safetensorsæ ¼å¼ï¼Œä½¿ç”¨transformersåŠ è½½")
                        from transformers import AutoModelForSpeechSeq2Seq
                        model = AutoModelForSpeechSeq2Seq.from_pretrained(
                            os.path.dirname(model_path),
                            local_files_only=True
                        )
                    else:
                        model = whisper.load_model(model_path)
                    
                    print("æ¨¡å‹åŠ è½½æˆåŠŸ")
                    
                except Exception as e2:
                    print(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e2}")


                    model = whisper.load_model(model_path)
                    print("ä½¿ç”¨whisper.load_modelåŠ è½½æˆåŠŸ")
                    
                except Exception as e2:
                    print(f"whisper.load_modelåŠ è½½å¤±è´¥: {e2}")
                    
                    # æ–¹æ³•3: ä½¿ç”¨torchç›´æ¥åŠ è½½æ¨¡å‹æ–‡ä»¶
                    if model_path.endswith(('.pt', '.bin', '.pth')):
                        try:
                            print(f"å°è¯•ä½¿ç”¨torch.loadåŠ è½½: {model_path}")
                            model_state = torch.load(model_path, map_location='cpu')
                            
                            # æ£€æŸ¥æ¨¡å‹çŠ¶æ€çš„ç»“æ„
                            if isinstance(model_state, dict):
                                if 'model_state_dict' in model_state:
                                    # è¿™æ˜¯ä¸€ä¸ªè®­ç»ƒcheckpointæ–‡ä»¶
                                    print("æ£€æµ‹åˆ°è®­ç»ƒcheckpointæ ¼å¼")
                                    # éœ€è¦å…ˆç¡®å®šæ¨¡å‹å¤§å°
                                    model_size = 'base'  # é»˜è®¤ä½¿ç”¨base
                                    if 'config' in model_state and 'n_mels' in model_state['config']:
                                        # æ ¹æ®é…ç½®æ¨æ–­æ¨¡å‹å¤§å°
                                        n_mels = model_state['config']['n_mels']
                                        if n_mels == 80:
                                            model_size = 'base'
                                    
                                    model = whisper.load_model(model_size)
                                    model.load_state_dict(model_state['model_state_dict'])
                                elif 'dims' in model_state or any(k.startswith('encoder.') or k.startswith('decoder.') for k in model_state.keys()):
                                    # è¿™å¯èƒ½æ˜¯ç›´æ¥çš„æ¨¡å‹çŠ¶æ€å­—å…¸
                                    print("æ£€æµ‹åˆ°æ¨¡å‹çŠ¶æ€å­—å…¸æ ¼å¼")
                                    # æ¨æ–­æ¨¡å‹å¤§å°
                                    model_size = 'base'  # é»˜è®¤
                                    model = whisper.load_model(model_size)
                                    model.load_state_dict(model_state)
                                else:
                                    raise ValueError(f"æ— æ³•è¯†åˆ«çš„æ¨¡å‹æ ¼å¼: {list(model_state.keys())[:5]}")
                            else:
                                raise ValueError(f"æ¨¡å‹æ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®ï¼ŒæœŸæœ›å­—å…¸ç±»å‹ï¼Œå¾—åˆ°: {type(model_state)}")
                        
                        except Exception as e3:
                            print(f"torch.loadä¹Ÿå¤±è´¥: {e3}")
                            raise ValueError(
                                f"æ— æ³•åŠ è½½æœ¬åœ°æ¨¡å‹ {model_path}ã€‚\n"
                                f"å°è¯•çš„æ–¹æ³•ï¼š\n"
                                f"1. transformersåº“: {str(e1)}\n"
                                f"2. whisper.load_model: {str(e2)}\n"
                                f"3. torch.load: {str(e3)}\n\n"
                                f"è¯·ç¡®ä¿æ¨¡å‹æ–‡ä»¶æ˜¯æœ‰æ•ˆçš„Whisperæ¨¡å‹æ ¼å¼ã€‚\n"
                                f"æ”¯æŒçš„æ ¼å¼ï¼š\n"
                                f"- Hugging Faceæ ¼å¼æ¨¡å‹ç›®å½•ï¼ˆæ¨èï¼‰\n"
                                f"- æ ‡å‡†Whisperæ¨¡å‹æ–‡ä»¶ (.pt)\n"
                                f"- è®­ç»ƒcheckpointæ–‡ä»¶ (.pt, .bin)\n"
                                f"- PyTorchæ¨¡å‹çŠ¶æ€å­—å…¸ (.pth)"
                            )
                    else:
                        raise e2
        else:
            # åœ¨çº¿æ¨¡å‹ï¼Œéœ€è¦ä¸‹è½½
            print(f"åŠ è½½åœ¨çº¿æ¨¡å‹: {model_name_or_path}ï¼Œä¸‹è½½è·¯å¾„: {download_root}")
            model = whisper.load_model(model_name_or_path, download_root=download_root)
        
        model_cache[cache_key] = model
        return model
    except Exception as e:
        raise gr.Error(f"æ— æ³•åŠ è½½æ¨¡å‹: {str(e)}")

def build_command(args, gpus):
    """æ„å»ºè®­ç»ƒå‘½ä»¤"""
    list_command = []
    
    # åˆ†å¸ƒå¼è®­ç»ƒ
    if gpus > 1:
        # å¤šå¡è®­ç»ƒï¼šä½¿ç”¨torchrunï¼Œä¸éœ€è¦python_execå‚æ•°
        list_command.extend([
            "torchrun", 
            f"--nproc_per_node={gpus}",
            "--master_port=29500"
        ])
    
    # æ ¹æ®è®­ç»ƒæ¨¡å¼é€‰æ‹©è„šæœ¬
    current_dir = os.path.dirname(os.path.abspath(__file__))
    if args['training_mode'] == "LoRAå¾®è°ƒ":
        finetune_script = os.path.join(current_dir, "finetune.py")
    else:  # å…¨å‚æ•°å¾®è°ƒ
        finetune_script = os.path.join(current_dir, "finetune_all.py")
    
    # ç¡®ä¿è„šæœ¬å­˜åœ¨
    if not os.path.exists(finetune_script):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°è®­ç»ƒè„šæœ¬: {finetune_script}")
    
    # æ·»åŠ è„šæœ¬è·¯å¾„
    if gpus > 1:
        # å¤šå¡è®­ç»ƒï¼šç›´æ¥æ·»åŠ è„šæœ¬è·¯å¾„
        list_command.append(finetune_script)
    else:
        # å•å¡è®­ç»ƒï¼šä½¿ç”¨å½“å‰Pythonè§£é‡Šå™¨
        import sys
        python_exec = sys.executable
        list_command.extend([python_exec, finetune_script])
    
    # æ•°æ®å‚æ•°
    list_command.extend([
        f"--train_data={args['train_data']}",
        f"--test_data={args['test_data']}",
        f"--min_audio_len={args['min_audio_len']}",
        f"--max_audio_len={args['max_audio_len']}",
    ])
    
    if args['augment_config_path']:
        list_command.append(f"--augment_config_path={args['augment_config_path']}")
    
    # æ¨¡å‹å‚æ•°
    list_command.extend([
        f"--base_model={args['base_model']}",
        f"--language={args['language']}",
        f"--task={args['task']}",
        f"--timestamps={'True' if args['timestamps'] else 'False'}",
        f"--fp16={'True' if args['fp16'] else 'False'}",
        f"--use_8bit={'True' if args['use_8bit'] else 'False'}",
    ])
    
    # æ ¹æ®è®­ç»ƒæ¨¡å¼æ·»åŠ ç‰¹å®šå‚æ•°
    if args['training_mode'] == "LoRAå¾®è°ƒ":
        list_command.append(f"--use_adalora={'True' if args['use_adalora'] else 'False'}")
    else:  # å…¨å‚æ•°å¾®è°ƒ
        list_command.append(f"--freeze_encoder={'True' if args['freeze_encoder'] else 'False'}")
    
    # è®­ç»ƒå‚æ•°
    list_command.extend([
        f"--output_dir={args['output_dir']}",
        f"--num_train_epochs={args['num_train_epochs']}",
        f"--learning_rate={args['learning_rate']}",
        f"--warmup_steps={args['warmup_steps']}",
        f"--per_device_train_batch_size={args['per_device_train_batch_size']}",
        f"--per_device_eval_batch_size={args['per_device_eval_batch_size']}",
        f"--gradient_accumulation_steps={args['gradient_accumulation_steps']}",
        f"--logging_steps={args['logging_steps']}",
        f"--eval_steps={args['eval_steps']}",
        f"--save_steps={args['save_steps']}",
        f"--num_workers={args['num_workers']}",
        f"--save_total_limit={args['save_total_limit']}",
    ])
    
    # é«˜çº§å‚æ•°
    if args['resume_from_checkpoint']:
        list_command.append(f"--resume_from_checkpoint={args['resume_from_checkpoint']}")
    
    list_command.extend([
        f"--local_files_only={'True' if args['local_files_only'] else 'False'}",
        f"--use_compile={'True' if args['use_compile'] else 'False'}",
        f"--push_to_hub={'True' if args['push_to_hub'] else 'False'}",
    ])
    
    if args['hub_model_id']:
        list_command.append(f"--hub_model_id={args['hub_model_id']}")
    
    # åˆ›å»ºå­—ç¬¦ä¸²å‘½ä»¤ç”¨äºæ˜¾ç¤º
    str_command = " ".join(list_command)
    return str_command, list_command

def run_training(list_command, output_file, log_callback=None):
    """è¿è¡Œè®­ç»ƒå‘½ä»¤å¹¶æ•è·è¾“å‡º"""
    global TRAINING_PROCESS, TRAINING_ACTIVE
    
    try:
        logger.info(f"æ‰§è¡Œå‘½ä»¤: {' '.join(list_command)}")
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_dir = os.path.dirname(output_file)
        if output_dir and not os.path.exists(output_dir):
            os.makedirs(output_dir)
        
        # ç›´æ¥å¯åŠ¨è®­ç»ƒè¿›ç¨‹å¹¶å®æ—¶æ•è·è¾“å‡º
        TRAINING_PROCESS = subprocess.Popen(
            list_command,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True,
            bufsize=1,
            universal_newlines=True,
        )
        
        logger.info(f"è®­ç»ƒè¿›ç¨‹å·²å¯åŠ¨ï¼ŒPID: {TRAINING_PROCESS.pid}")
        
        # æ‰“å¼€æ—¥å¿—æ–‡ä»¶ç”¨äºå†™å…¥
        with open(output_file, "w", encoding="utf-8") as log_file:
            # å®æ—¶è¯»å–è¿›ç¨‹è¾“å‡º
            while TRAINING_ACTIVE and TRAINING_PROCESS.poll() is None:
                try:
                    line = TRAINING_PROCESS.stdout.readline()
                    if line:
                        line = line.rstrip('\n\r')
                        # å†™å…¥æ—¥å¿—æ–‡ä»¶
                        log_file.write(line + '\n')
                        log_file.flush()
                        
                        # å›è°ƒå‡½æ•°å¤„ç†
                        if log_callback:
                            log_callback(line)
                        
                        # è¿”å›ç»™ç•Œé¢æ˜¾ç¤º
                        yield line + '\n'
                    else:
                        time.sleep(0.1)
                except Exception as e:
                    logger.error(f"è¯»å–è¾“å‡ºæ—¶å‡ºé”™: {e}")
                    break
            
            # è¯»å–å‰©ä½™è¾“å‡º
            remaining_output = TRAINING_PROCESS.stdout.read()
            if remaining_output:
                log_file.write(remaining_output)
                log_file.flush()
                yield remaining_output
        
        # ç­‰å¾…è¿›ç¨‹ç»“æŸ
        return_code = TRAINING_PROCESS.wait()
        
        # æ£€æŸ¥é€€å‡ºçŠ¶æ€
        if return_code == 0:
            yield "\n\nâœ… è®­ç»ƒæˆåŠŸå®Œæˆ!"
        else:
            yield f"\n\nâŒ è®­ç»ƒå¤±è´¥ï¼Œé€€å‡ºç : {return_code}"
    
    except Exception as e:
        logger.error(f"è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        yield f"\n\nâŒ å‘ç”Ÿé”™è¯¯: {str(e)}"
    finally:
        TRAINING_PROCESS = None
        TRAINING_ACTIVE = False

def save_command_script(command_str, output_dir, training_mode="LoRAå¾®è°ƒ"):
    """å°†è®­ç»ƒå‘½ä»¤ä¿å­˜ä¸ºshellè„šæœ¬æ–‡ä»¶"""
    try:
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(output_dir, exist_ok=True)
        
        # æ ¹æ®è®­ç»ƒæ¨¡å¼ç”Ÿæˆä¸åŒçš„æ–‡ä»¶å
        timestamp = time.strftime("%Y%m%d-%H%M%S")
        if training_mode == "LoRAå¾®è°ƒ":
            script_filename = f"train_lora_{timestamp}.sh"
            script_type = "LoRAå¾®è°ƒ"
        else:
            script_filename = f"train_full_{timestamp}.sh"
            script_type = "å…¨å‚æ•°å¾®è°ƒ"
        
        script_path = os.path.join(output_dir, script_filename)
        
        # å†™å…¥æ–‡ä»¶
        with open(script_path, "w", encoding="utf-8") as f:
            f.write("#!/bin/bash\n")
            f.write(f"# Whisper {script_type}è®­ç»ƒå‘½ä»¤è„šæœ¬\n")
            f.write(f"# ç”Ÿæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"# è®­ç»ƒæ¨¡å¼: {training_mode}\n\n")
            
            # æ·»åŠ ä½¿ç”¨è¯´æ˜
            f.write("# ä½¿ç”¨è¯´æ˜:\n")
            if training_mode == "LoRAå¾®è°ƒ":
                f.write("# æ­¤è„šæœ¬ç”¨äºLoRAå¾®è°ƒè®­ç»ƒï¼Œå‚æ•°æ•ˆç‡é«˜ï¼Œæ˜¾å­˜å ç”¨å°‘\n")
                f.write("# è®­ç»ƒå®Œæˆåéœ€è¦ä½¿ç”¨æ¨¡å‹åˆå¹¶åŠŸèƒ½å°†LoRAé€‚é…å™¨åˆå¹¶åˆ°åŸºç¡€æ¨¡å‹\n")
            else:
                f.write("# æ­¤è„šæœ¬ç”¨äºå…¨å‚æ•°å¾®è°ƒè®­ç»ƒï¼Œæ•ˆæœæ›´å¥½ä½†æ˜¾å­˜å ç”¨å¤§\n")
                f.write("# è®­ç»ƒå®Œæˆåç›´æ¥å¾—åˆ°å®Œæ•´çš„å¾®è°ƒæ¨¡å‹ï¼Œæ— éœ€é¢å¤–åˆå¹¶æ­¥éª¤\n")
            f.write("# æ‰§è¡Œå‰è¯·ç¡®ä¿å·²å®‰è£…æ‰€éœ€ä¾èµ–å’Œé…ç½®å¥½ç¯å¢ƒ\n\n")
            
            f.write(command_str + "\n")
        
        # æ·»åŠ æ‰§è¡Œæƒé™ï¼ˆWindowsä¸‹å¯èƒ½ä¸æ”¯æŒï¼Œä½†ä¸ä¼šæŠ¥é”™ï¼‰
        try:
            os.chmod(script_path, 0o755)
        except:
            pass  # Windowsä¸‹å¿½ç•¥æƒé™è®¾ç½®é”™è¯¯
        
        return script_path
    except Exception as e:
        print(f"ä¿å­˜è®­ç»ƒè„šæœ¬å¤±è´¥: {e}")
        return None

def start_training(
    train_data,
    test_data,
    augment_config_path,
    min_audio_len,
    max_audio_len,
    base_model,
    language,
    task,
    training_mode,
    timestamps,
    use_adalora,
    freeze_encoder,
    fp16,
    use_8bit,
    output_dir,
    num_train_epochs,
    learning_rate,
    warmup_steps,
    per_device_train_batch_size,
    per_device_eval_batch_size,
    gradient_accumulation_steps,
    logging_steps,
    eval_steps,
    save_steps,
    num_workers,
    save_total_limit,
    resume_from_checkpoint,
    local_files_only,
    use_compile,
    push_to_hub,
    hub_model_id,
    gpus,
    save_command_script_flag  # æ–°å¢å‚æ•°
):
    global TRAINING_THREAD, OUTPUT_FILE, TRAINING_ACTIVE
    
    if TRAINING_ACTIVE:
        yield "âš ï¸ å½“å‰å·²æœ‰è®­ç»ƒæ­£åœ¨è¿›è¡Œï¼Œè¯·ç­‰å¾…å®Œæˆåå†å¯åŠ¨æ–°è®­ç»ƒã€‚", "", None
        return
    
    # å‡†å¤‡å‚æ•°
    args = {
        "train_data": train_data,
        "test_data": test_data,
        "augment_config_path": augment_config_path,
        "min_audio_len": min_audio_len,
        "max_audio_len": max_audio_len,
        "base_model": base_model,
        "language": language,
        "task": task,
        "training_mode": training_mode,
        "timestamps": timestamps,
        "use_adalora": use_adalora,
        "freeze_encoder": freeze_encoder,
        "fp16": fp16,
        "use_8bit": use_8bit,
        "output_dir": output_dir,
        "num_train_epochs": num_train_epochs,
        "learning_rate": learning_rate,
        "warmup_steps": warmup_steps,
        "per_device_train_batch_size": per_device_train_batch_size,
        "per_device_eval_batch_size": per_device_eval_batch_size,
        "gradient_accumulation_steps": gradient_accumulation_steps,
        "logging_steps": logging_steps,
        "eval_steps": eval_steps,
        "save_steps": save_steps,
        "num_workers": num_workers,
        "save_total_limit": save_total_limit,
        "resume_from_checkpoint": resume_from_checkpoint,
        "local_files_only": local_files_only,
        "use_compile": use_compile,
        "push_to_hub": push_to_hub,
        "hub_model_id": hub_model_id,
    }
    
    # æ„å»ºå‘½ä»¤
    str_command, list_command = build_command(args, gpus)
    
    # åˆ›å»ºè¾“å‡ºæ–‡ä»¶
    timestamp = time.strftime("%Y%m%d-%H%M%S")
    OUTPUT_FILE = f"training_logs/train_{timestamp}.log"
    
    # ä¿å­˜è®­ç»ƒå‘½ä»¤ä¸ºè„šæœ¬ï¼ˆå¦‚æœç”¨æˆ·é€‰æ‹©ï¼‰
    script_path = None
    if save_command_script_flag:
        script_path = save_command_script(str_command, output_dir, training_mode)
        script_info = f"\n\nğŸ“œ è®­ç»ƒå‘½ä»¤å·²ä¿å­˜ä¸ºè„šæœ¬: {script_path}" if script_path else "\n\nâš ï¸ ä¿å­˜è®­ç»ƒè„šæœ¬å¤±è´¥"
    else:
        script_info = ""
    
    TRAINING_ACTIVE = True
    
    # å…ˆè¿”å›å‘½ä»¤é¢„è§ˆ
    initial_output = f"è®­ç»ƒå‘½ä»¤é¢„è§ˆ:\n{str_command}{script_info}\n\nå¼€å§‹è®­ç»ƒ...\næ—¥å¿—æ–‡ä»¶: {OUTPUT_FILE}\n"
    yield initial_output, str_command, script_path
    
    # è¿è¡Œè®­ç»ƒå¹¶å®æ—¶è¿”å›è¾“å‡º
    accumulated_output = initial_output
    
    for line in run_training(list_command, OUTPUT_FILE):
        accumulated_output += line
        yield accumulated_output, str_command, script_path

def stop_training():
    global TRAINING_PROCESS, TRAINING_ACTIVE
    
    if TRAINING_PROCESS and TRAINING_ACTIVE:
        # ç»ˆæ­¢æ•´ä¸ªè¿›ç¨‹ç»„
        try:
            if platform.system() == "Windows":
                subprocess.Popen(["taskkill", "/F", "/T", "/PID", str(TRAINING_PROCESS.pid)])
            else:
                os.killpg(os.getpgid(TRAINING_PROCESS.pid), signal.SIGTERM)
            TRAINING_ACTIVE = False
            return "ğŸ›‘ è®­ç»ƒå·²åœæ­¢", ""
        except Exception as e:
            return f"åœæ­¢è®­ç»ƒå¤±è´¥: {str(e)}", ""
    return "âš ï¸ æ²¡æœ‰æ­£åœ¨è¿›è¡Œçš„è®­ç»ƒ", ""

def get_log_content():
    if OUTPUT_FILE and os.path.exists(OUTPUT_FILE):
        with open(OUTPUT_FILE, "r") as f:
            return f.read()
    return "æš‚æ— æ—¥å¿—"

# ============================== æ­¥éª¤3: æ¨¡å‹åˆå¹¶åŠŸèƒ½ ==============================
def merge_models(lora_model, output_dir, local_files_only):
    """åˆå¹¶LoRAæ¨¡å‹åˆ°åŸºç¡€æ¨¡å‹"""
    try:
        start_time = time.time()
        
        # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(lora_model):
            return f"é”™è¯¯ï¼šæ¨¡å‹æ–‡ä»¶ {lora_model} ä¸å­˜åœ¨ï¼"
        
        # è·å–Loraé…ç½®å‚æ•°
        peft_config = PeftConfig.from_pretrained(lora_model)
        
        # è·å–Whisperçš„åŸºæœ¬æ¨¡å‹
        base_model = WhisperForConditionalGeneration.from_pretrained(
            peft_config.base_model_name_or_path, 
            device_map={"": "cpu"},
            local_files_only=local_files_only
        )
        
        # ä¸Loraæ¨¡å‹åˆå¹¶
        model = PeftModel.from_pretrained(base_model, lora_model, local_files_only=local_files_only)
        feature_extractor = WhisperFeatureExtractor.from_pretrained(
            peft_config.base_model_name_or_path,
            local_files_only=local_files_only
        )
        tokenizer = WhisperTokenizerFast.from_pretrained(
            peft_config.base_model_name_or_path,
            local_files_only=local_files_only
        )
        processor = WhisperProcessor.from_pretrained(
            peft_config.base_model_name_or_path,
            local_files_only=local_files_only
        )
        
        # åˆå¹¶å‚æ•°
        model = model.merge_and_unload()
        model.train(False)
        
        # ä¿å­˜çš„æ–‡ä»¶å¤¹è·¯å¾„
        if peft_config.base_model_name_or_path.endswith("/"):
            peft_config.base_model_name_or_path = peft_config.base_model_name_or_path[:-1]
        save_directory = os.path.join(output_dir, f'{os.path.basename(peft_config.base_model_name_or_path)}-finetune')
        os.makedirs(save_directory, exist_ok=True)
        
        # ä¿å­˜æ¨¡å‹åˆ°æŒ‡å®šç›®å½•ä¸­
        model.save_pretrained(save_directory, max_shard_size='4GB')
        feature_extractor.save_pretrained(save_directory)
        tokenizer.save_pretrained(save_directory)
        processor.save_pretrained(save_directory)
        
        elapsed = time.time() - start_time
        return f"æ¨¡å‹åˆå¹¶æˆåŠŸï¼ä¿å­˜åœ¨: {save_directory}\nè€—æ—¶: {elapsed:.2f}ç§’"
    except Exception as e:
        traceback.print_exc()
        return f"æ¨¡å‹åˆå¹¶å¤±è´¥: {str(e)}"

# ============================== æ­¥éª¤4: æ¨¡å‹ä½¿ç”¨åŠŸèƒ½ ==============================
def transcribe_audio(model_name, file_path, task, language, custom_model_path, download_root, model_type):
    """æ‰§è¡Œè¯­éŸ³è¯†åˆ«æˆ–ç¿»è¯‘"""
    # æ ¹æ®æ¨¡å‹ç±»å‹é€‰æ‹©åŠ è½½æ–¹å¼
    if model_type == "æœ¬åœ°æ¨¡å‹":
        if not custom_model_path or not os.path.exists(custom_model_path):
            return "è¯·æä¾›æœ‰æ•ˆçš„æœ¬åœ°æ¨¡å‹è·¯å¾„", "", ""
        model_path = custom_model_path
        is_local = True
    else:  # åœ¨çº¿æ¨¡å‹
        model_path = model_name
        is_local = False
    
    try:
        model = load_model(model_path, download_root, is_local)
    except Exception as e:
        return str(e), "", ""
    
    # è®¾ç½®è¯­è¨€å‚æ•°
    lang = None if language == "è‡ªåŠ¨æ£€æµ‹" else language
    
    # æ£€æŸ¥æ¨¡å‹ç±»å‹å¹¶ç›¸åº”å¤„ç†
    if hasattr(model, 'pipe'):  # TransformersWhisperModel
        # ä½¿ç”¨transformers pipeline
        generate_kwargs = {"task": task}
        if lang:
            generate_kwargs["language"] = lang
        
        try:
            result = model.pipe(file_path, return_timestamps=True, generate_kwargs=generate_kwargs)
            
            # æ ¼å¼åŒ–ç»“æœ
            if "chunks" in result:
                formatted_chunks = []
                for chunk in result["chunks"]:
                    # å®‰å…¨å¤„ç†æ—¶é—´æˆ³
                    start = chunk['timestamp'][0] if chunk['timestamp'] and chunk['timestamp'][0] is not None else 0.0
                    end = chunk['timestamp'][1] if chunk['timestamp'] and chunk['timestamp'][1] is not None else 0.0
                    
                    # ç¡®ä¿æ—¶é—´æˆ³æ˜¯æ•°å­—ç±»å‹
                    try:
                        start = float(start)
                        end = float(end)
                    except (TypeError, ValueError):
                        start, end = 0.0, 0.0
                    
                    formatted_chunks.append(f"[{start:.2f}s - {end:.2f}s] {chunk['text']}")
                
                text = "\n".join(formatted_chunks)
            else:
                text = result.get("text", "")
            
            detected_lang = lang if lang else "auto"
            detected_lang_name = LANGUAGES.get(detected_lang, detected_lang) if detected_lang != "auto" else "è‡ªåŠ¨æ£€æµ‹"
            
            return text, detected_lang_name, detected_lang
        except Exception as e:
            return f"transformersæ¨¡å‹æ¨ç†å¤±è´¥: {str(e)}", "", ""
    else:
        # ä½¿ç”¨æ ‡å‡†whisperæ¨¡å‹
        try:
            result = model.transcribe(
                file_path,
                task=task,
                language=lang
            )
            
            # è·å–æ£€æµ‹åˆ°çš„è¯­è¨€
            detected_lang = result.get("language", "æœªçŸ¥")
            detected_lang_name = LANGUAGES.get(detected_lang, detected_lang)
            
            return result["text"], detected_lang_name, detected_lang
        except Exception as e:
            return f"whisperæ¨¡å‹æ¨ç†å¤±è´¥: {str(e)}", "", ""

def process_file(file, model_name, task, language, custom_model_path, download_root, model_type):
    """å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶"""
    audio_path = None
    
    try:
        # å¦‚æœæ˜¯è§†é¢‘æ–‡ä»¶ï¼Œå…ˆæå–éŸ³é¢‘
        if isinstance(file, str) and file.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')):
            try:
                import ffmpeg
                # åœ¨Gradioä¸´æ—¶ç›®å½•ä¸­åˆ›å»ºéŸ³é¢‘æ–‡ä»¶
                with tempfile.NamedTemporaryFile(suffix=".wav", delete=False, dir=temp_dir) as tmpfile:
                    audio_path = tmpfile.name
                
                # ä½¿ç”¨ffmpegæå–éŸ³é¢‘
                (
                    ffmpeg
                    .input(file)
                    .output(audio_path, ac=1, ar=16000)
                    .overwrite_output()
                    .run(quiet=True)
                )
                file_path = audio_path
            except ImportError:
                return "å¤„ç†è§†é¢‘éœ€è¦ffmpeg-pythonåº“ï¼Œè¯·å®‰è£…: pip install ffmpeg-python", "", "", ""
            except Exception as e:
                return f"è§†é¢‘å¤„ç†å¤±è´¥: {str(e)}", "", "", ""
        else:
            file_path = file
        
        # æ‰§è¡Œè¯†åˆ«/ç¿»è¯‘
        text, detected_lang, lang_code = transcribe_audio(model_name, file_path, task, language, custom_model_path, download_root, model_type)
        
        # è¿”å›æ–‡æœ¬ã€æ£€æµ‹è¯­è¨€ã€è¯­è¨€ä»£ç ã€éŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºä¿å­˜ï¼‰
        return text, detected_lang, lang_code, audio_path or file_path
    
    except Exception as e:
        return f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}", "", "", ""
    finally:
        # æ¸…ç†ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶ï¼ˆå¦‚æœæ˜¯è§†é¢‘è½¬æ¢ç”Ÿæˆçš„ï¼‰
        if audio_path and os.path.exists(audio_path):
            try:
                os.unlink(audio_path)
            except:
                pass

def update_language_visibility(task):
    """æ ¹æ®ä»»åŠ¡ç±»å‹æ›´æ–°è¯­è¨€é€‰æ‹©çš„å¯è§æ€§"""
    return gr.Dropdown(visible=task != "translate")

def update_model_interface(model_type):
    """æ ¹æ®æ¨¡å‹ç±»å‹æ›´æ–°ç•Œé¢æ˜¾ç¤º"""
    if model_type == "åœ¨çº¿æ¨¡å‹":
        return (
            gr.Dropdown(label="é€‰æ‹©åœ¨çº¿æ¨¡å‹", visible=True),  # model_choice
            gr.Textbox(label="æœ¬åœ°æ¨¡å‹è·¯å¾„", visible=False),  # custom_model_path
            gr.Textbox(label="æ¨¡å‹ä¸‹è½½è·¯å¾„ (ä»…åœ¨çº¿æ¨¡å‹)", visible=True)  # download_root_input
        )
    else:  # æœ¬åœ°æ¨¡å‹
        return (
            gr.Dropdown(label="é€‰æ‹©åœ¨çº¿æ¨¡å‹", visible=False),  # model_choice
            gr.Textbox(label="æœ¬åœ°æ¨¡å‹è·¯å¾„", visible=True),  # custom_model_path
            gr.Textbox(label="æ¨¡å‹ä¸‹è½½è·¯å¾„ (ä»…åœ¨çº¿æ¨¡å‹)", visible=False)  # download_root_input
        )

def update_training_mode_interface(training_mode):
    """æ ¹æ®è®­ç»ƒæ¨¡å¼æ›´æ–°ç•Œé¢æ˜¾ç¤º"""
    if training_mode == "LoRAå¾®è°ƒ":
        return (
            gr.Checkbox(label="ä½¿ç”¨AdaLora", visible=True),  # use_adalora
            gr.Checkbox(label="å†»ç»“ç¼–ç å™¨", visible=False)   # freeze_encoder
        )
    else:  # å…¨å‚æ•°å¾®è°ƒ
        return (
            gr.Checkbox(label="ä½¿ç”¨AdaLora", visible=False), # use_adalora
            gr.Checkbox(label="å†»ç»“ç¼–ç å™¨", visible=True)    # freeze_encoder
        )

def save_dataset_entry(text, audio_path, output_dir):
    """ä¿å­˜æ•°æ®é›†æ¡ç›®åˆ°JSONæ–‡ä»¶"""
    if not audio_path or not isinstance(audio_path, str):
        return "éŸ³é¢‘æ–‡ä»¶è·¯å¾„æ— æ•ˆï¼Œæ— æ³•ä¿å­˜"
    
    if not os.path.exists(audio_path):
        return "éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ— æ³•ä¿å­˜"
    
    if not text.strip():
        return "æ–‡æœ¬å†…å®¹ä¸ºç©ºï¼Œæ— æ³•ä¿å­˜"
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(output_dir, exist_ok=True)
    
    # åˆ›å»ºæ•°æ®é›†æ–‡ä»¶è·¯å¾„
    dataset_path = os.path.join(output_dir, "dataset.json")
    
    # å¤åˆ¶éŸ³é¢‘æ–‡ä»¶åˆ°è¾“å‡ºç›®å½•
    audio_filename = os.path.basename(audio_path)
    target_audio_path = os.path.join(output_dir, audio_filename)
    
    try:
        # å¤åˆ¶éŸ³é¢‘æ–‡ä»¶
        import shutil
        shutil.copy(audio_path, target_audio_path)
        
        # åˆ›å»ºæˆ–æ›´æ–°æ•°æ®é›†JSON
        entry = {
            "audio_filepath": audio_filename,
            "text": text.strip()
        }
        
        # å¦‚æœæ–‡ä»¶å­˜åœ¨ï¼Œç›´æ¥è¿½åŠ ï¼›å¦‚æœä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°æ–‡ä»¶
        with open(dataset_path, "a", encoding="utf-8") as f:
            f.write(json.dumps(entry, ensure_ascii=False) + '\n')
        
        # è®¡ç®—æ¡ç›®æ€»æ•°
        count = 0
        if os.path.exists(dataset_path):
            with open(dataset_path, "r", encoding="utf-8") as f:
                count = sum(1 for _ in f)
            
        return f"âœ… å·²ä¿å­˜åˆ°æ•°æ®é›†! æ¡ç›®æ€»æ•°: {count}"
    except Exception as e:
        return f"ä¿å­˜å¤±è´¥: {str(e)}"

# ============================== Gradioç•Œé¢ ==============================
# å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨
MODEL_OPTIONS = ["tiny", "base", "small", "medium", "large", "large-v2", "large-v3", "turbo"]

# è¯­è¨€é€‰é¡¹
language_names = sorted(LANGUAGES.values())
language_options = ["è‡ªåŠ¨æ£€æµ‹"] + language_names

# åˆ›å»ºGradioç•Œé¢
with gr.Blocks(theme=gr.themes.Ocean(), title="Whisper è®­ç»ƒå·¥å…·å¥—ä»¶") as demo:
    gr.Markdown("# ğŸ¤ Whisper è¯­éŸ³è¯†åˆ«æ¨¡å‹è®­ç»ƒå¹³å°")
    gr.Markdown("Whisper æ¨¡å‹è®­ç»ƒå·¥ä½œå°ï¼Œæ•°æ®é›†å‡†å¤‡å’Œè®­ç»ƒ")
    
    # ======================= æ­¥éª¤1: æ•°æ®å‡†å¤‡ =======================
    with gr.Tab("æ­¥éª¤1: æ•°æ®å‡†å¤‡", id="data_preparation"):
        gr.Markdown("""### æ•°æ®å‡†å¤‡
        **ä¸Šä¼ CSV/Excelæ–‡ä»¶ï¼Œé€‰æ‹©å¯¹åº”åˆ—ç”ŸæˆWhisperè®­ç»ƒæ‰€éœ€çš„JSONæ ¼å¼**
        """)
        
        with gr.Row():
            with gr.Column(scale=1):
                file_input = gr.File(
                    label="ä¸Šä¼ æ•°æ®æ–‡ä»¶ (CSV/Excel)", 
                    type="filepath",
                    file_types=[".csv", ".xls", ".xlsx"]
                )
                gr.Markdown("æ”¯æŒCSVå’ŒExcelæ ¼å¼")
                
                gr.Markdown("### å­—æ®µæ˜ å°„")
                audio_col = gr.Dropdown(
                    label="éŸ³é¢‘è·¯å¾„åˆ—", 
                    choices=["ä¸é€‰æ‹©"],
                    value="ä¸é€‰æ‹©",
                    interactive=True
                )
                text_col = gr.Dropdown(
                    label="æ–‡æœ¬åˆ—", 
                    choices=["ä¸é€‰æ‹©"],
                    value="ä¸é€‰æ‹©",
                    interactive=True
                )
                
                language_col = gr.Dropdown(
                    label="è¯­è¨€åˆ—", 
                    choices=["ä¸é€‰æ‹©"],
                    value="ä¸é€‰æ‹©",
                    interactive=True
                )
                
                gr.Markdown("### åˆ†æ®µä¿¡æ¯ (å¯é€‰)")
                with gr.Row():
                    start_col = gr.Dropdown(
                        label="å¼€å§‹æ—¶é—´åˆ—", 
                        choices=["ä¸é€‰æ‹©"],
                    value="ä¸é€‰æ‹©",
                    interactive=True
                )
                end_col = gr.Dropdown(
                    label="ç»“æŸæ—¶é—´åˆ—", 
                        choices=["ä¸é€‰æ‹©"],
                    value="ä¸é€‰æ‹©",
                    interactive=True
                )
                segment_text_col = gr.Dropdown(
                    label="åˆ†æ®µæ–‡æœ¬åˆ—", 
                    choices=["ä¸é€‰æ‹©"],
                    value="ä¸é€‰æ‹©",
                    interactive=True
                )
                
                output_dir = gr.Textbox(
                    label="è¾“å‡ºç›®å½•", 
                    value="./whisper_dataset"
                )
                
            with gr.Column(scale=1):
                
                gr.Markdown("### é«˜çº§é€‰é¡¹")
                with gr.Row():
                    include_sentences = gr.Checkbox(
                        label="åŒ…å«sentenceså­—æ®µ",
                        value=False
                    )
                    include_duration = gr.Checkbox(
                        label="åŒ…å«durationå­—æ®µ",
                        value=True
                    )
                
                    add_punctuation = gr.Checkbox(
                        label="æ·»åŠ æ ‡ç‚¹æ¢å¤",
                        value=False
                    )
                    auto_calc_duration = gr.Checkbox(
                        label="è‡ªåŠ¨è®¡ç®—éŸ³é¢‘æ—¶é•¿",
                        value=True
                    )
                    
                gr.Markdown("### æ•°æ®é›†åˆ’åˆ†")
                with gr.Row():
                    enable_split = gr.Checkbox(
                        label="å¯ç”¨æ•°æ®é›†åˆ’åˆ†",
                        value=False
                    )
                    train_ratio = gr.Slider(
                        label="è®­ç»ƒé›†æ¯”ä¾‹",
                        minimum=0.1,
                        maximum=0.9,
                        value=0.8,
                        step=0.05
                    )
                
                generate_btn = gr.Button("ç”Ÿæˆæ•°æ®é›†", variant="primary", size="lg")

                gr.Markdown("### æ•°æ®é¢„è§ˆ")
                preview_table = gr.Dataframe(
                    interactive=False,
                    wrap=True
                )
                
                gr.Markdown("### ç”Ÿæˆç»“æœ")
                output_result = gr.Textbox(
                    label="è¾“å‡ºä¿¡æ¯",
                    interactive=False,
                    lines=4
                )
        
        # å½“æ–‡ä»¶ä¸Šä¼ æ—¶æ›´æ–°æ‰€æœ‰ç»„ä»¶
        def update_all_components(input_file):
            preview, options = data_prep_update_preview(input_file)
            return [
                preview,
                gr.update(choices=options),
                gr.update(choices=options),
                gr.update(choices=options),
                gr.update(choices=options),
                gr.update(choices=options),
                gr.update(choices=options)
            ]
        
        # æ–‡ä»¶ä¸Šä¼ æ—¶æ›´æ–°æ‰€æœ‰ä¸‹æ‹‰æ¡†é€‰é¡¹å’Œé¢„è§ˆ
        file_input.change(
            fn=update_all_components,
            inputs=file_input,
            outputs=[
                preview_table,
                audio_col,
                text_col,
                language_col,
                start_col,
                end_col,
                segment_text_col
            ]
        )
        
        # ç”ŸæˆJSONæ–‡ä»¶
        generate_btn.click(
            fn=data_prep_generate_json,
            inputs=[
                file_input,
                audio_col,
                text_col,
                language_col,
                start_col,
                end_col,
                segment_text_col,
                output_dir,
                include_sentences,
                include_duration,
                train_ratio,
                enable_split,
                add_punctuation,
                auto_calc_duration
            ],
            outputs=output_result
        )
    
    # ======================= æ­¥éª¤2: æ¨¡å‹è®­ç»ƒ =======================
    with gr.Tab("æ­¥éª¤2: æ¨¡å‹è®­ç»ƒ", id="model_training"):
        gr.Markdown("### è®­ç»ƒå‚æ•°è®¾ç½®")
        
        with gr.Row():
            with gr.Column(scale=1):
                gr.Markdown("#### æ•°æ®è®¾ç½®")
                with gr.Row():
                    train_data = gr.Textbox(label="è®­ç»ƒæ•°æ®é›†è·¯å¾„", value="./whisper_dataset/train.jsonl")
                    test_data = gr.Textbox(label="æµ‹è¯•æ•°æ®é›†è·¯å¾„", value="./whisper_dataset/test.jsonl")
                augment_config_path = gr.Textbox(label="å¢å¼ºé…ç½®æ–‡ä»¶è·¯å¾„", placeholder="å¯é€‰ï¼Œç•™ç©ºåˆ™ä¸ä½¿ç”¨å¢å¼º")
                with gr.Row():
                    min_audio_len = gr.Number(label="æœ€å°éŸ³é¢‘é•¿åº¦(ç§’)", value=0.5)
                    max_audio_len = gr.Number(label="æœ€å¤§éŸ³é¢‘é•¿åº¦(ç§’)", value=30.0)
                
                gr.Markdown("#### æ¨¡å‹è®¾ç½®")
                base_model = gr.Textbox(label="åŸºç¡€æ¨¡å‹", value="./whisper-large-v3-turbo")
                language = gr.Dropdown(label="è¯­è¨€", choices=["Chinese", "English", "Japanese", "Multilingual"], value="Chinese")
                task = gr.Dropdown(label="ä»»åŠ¡", choices=["transcribe", "translate"], value="transcribe")
                
                # è®­ç»ƒæ¨¡å¼é€‰æ‹©
                training_mode = gr.Radio(
                    label="è®­ç»ƒæ¨¡å¼",
                    choices=["LoRAå¾®è°ƒ", "å…¨å‚æ•°å¾®è°ƒ"],
                    value="LoRAå¾®è°ƒ",
                    info="LoRAå¾®è°ƒï¼šå‚æ•°æ•ˆç‡é«˜ï¼Œæ˜¾å­˜å ç”¨å°‘ï¼›å…¨å‚æ•°å¾®è°ƒï¼šæ•ˆæœæ›´å¥½ï¼Œæ˜¾å­˜å ç”¨å¤§"
                )
                
                with gr.Row():
                    timestamps = gr.Checkbox(label="ä½¿ç”¨æ—¶é—´æˆ³", value=False)
                    # LoRAç›¸å…³å‚æ•°ï¼Œä»…åœ¨LoRAæ¨¡å¼ä¸‹æ˜¾ç¤º
                    use_adalora = gr.Checkbox(label="ä½¿ç”¨AdaLora", value=True, visible=True)
                
                # å…¨å‚æ•°å¾®è°ƒä¸“ç”¨å‚æ•°
                freeze_encoder = gr.Checkbox(
                    label="å†»ç»“ç¼–ç å™¨", 
                    value=True, 
                    visible=False,
                    info="ä»…è®­ç»ƒè§£ç å™¨å‚æ•°ï¼Œå‡å°‘æ˜¾å­˜å ç”¨"
                )
                
                with gr.Row():
                    fp16 = gr.Checkbox(label="FP16è®­ç»ƒ", value=True)
                    use_8bit = gr.Checkbox(label="8-bité‡åŒ–", value=False)
            
                gr.Markdown("#### é«˜çº§è®¾ç½®")
                # æ–°å¢ä¿å­˜è„šæœ¬é€‰é¡¹
                save_command_script_flag = gr.Checkbox(
                   label="ä¿å­˜è®­ç»ƒå‘½ä»¤ä¸ºè„šæœ¬æ–‡ä»¶",
                   value=True,
                   info="å°†è®­ç»ƒå‚æ•°ä¿å­˜ä¸ºå¯æ‰§è¡Œçš„Shellè„šæœ¬")
                resume_from_checkpoint = gr.Textbox(label="æ¢å¤è®­ç»ƒæ£€æŸ¥ç‚¹", placeholder="å¯é€‰ï¼Œä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ")
                local_files_only = gr.Checkbox(label="ä»…ä½¿ç”¨æœ¬åœ°æ¨¡å‹", value=False)
                use_compile = gr.Checkbox(label="ä½¿ç”¨PyTorchç¼–è¯‘", value=False)
                push_to_hub = gr.Checkbox(label="æ¨é€æ¨¡å‹åˆ°HuggingFace Hub", value=False)
                hub_model_id = gr.Textbox(label="Hubæ¨¡å‹ID", placeholder="HuggingFace Hubæ¨¡å‹ID")
            
            with gr.Column(scale=1):
                gr.Markdown("#### è®­ç»ƒè®¾ç½®")
                output_dir = gr.Textbox(label="è¾“å‡ºç›®å½•", value="./whisper_output/")
                num_train_epochs = gr.Number(label="è®­ç»ƒè½®æ•°", value=3)
                learning_rate = gr.Number(label="å­¦ä¹ ç‡", value=1e-3)
                warmup_steps = gr.Number(label="é¢„çƒ­æ­¥æ•°", value=50)
                with gr.Row():
                    per_device_train_batch_size = gr.Number(label="è®­ç»ƒbatch size", value=8)
                    per_device_eval_batch_size = gr.Number(label="è¯„ä¼°batch size", value=8)
                gradient_accumulation_steps = gr.Number(label="æ¢¯åº¦ç´¯ç§¯æ­¥æ•°", value=1)
                with gr.Row():
                    logging_steps = gr.Number(label="æ—¥å¿—æ‰“å°æ­¥æ•°", value=100)
                    eval_steps = gr.Number(label="è¯„ä¼°æ­¥æ•°", value=1000)
                    save_steps = gr.Number(label="ä¿å­˜æ­¥æ•°", value=1000)
                with gr.Row():
                    num_workers = gr.Number(label="æ•°æ®åŠ è½½çº¿ç¨‹æ•°", value=8)
                    save_total_limit = gr.Number(label="ä¿å­˜çš„æ£€æŸ¥ç‚¹æ•°é‡", value=10)
                gpus = gr.Number(label="GPUæ•°é‡", value=1, precision=0)
        
        
        with gr.Row():
            start_btn = gr.Button("ğŸš€ å¼€å§‹è®­ç»ƒ", variant="primary")
            stop_btn = gr.Button("ğŸ›‘ åœæ­¢è®­ç»ƒ")
        
        with gr.Row():
            gr.Markdown("### è®­ç»ƒå‘½ä»¤é¢„è§ˆ")
            command_preview = gr.Textbox(label="å°†æ‰§è¡Œçš„å‘½ä»¤", lines=3, interactive=False)
        
        with gr.Row():
            output_log = gr.Textbox(label="è®­ç»ƒè¾“å‡º", lines=20, interactive=False, autoscroll=True)
        # æ–°å¢è®­ç»ƒè„šæœ¬ä¸‹è½½ç»„ä»¶
        with gr.Row():
           script_output = gr.File(
              label="è®­ç»ƒè„šæœ¬",
              interactive=False,
              visible=False)
        
        # è®¾ç½®è®­ç»ƒæ¨¡å¼åˆ‡æ¢äº‹ä»¶
        training_mode.change(
            fn=update_training_mode_interface,
            inputs=[training_mode],
            outputs=[use_adalora, freeze_encoder]
        )
        
        # å­˜å‚¨æ‰€æœ‰è¾“å…¥ç»„ä»¶
        all_input_components = [
            train_data, test_data, augment_config_path, min_audio_len, max_audio_len,
            base_model, language, task, training_mode, timestamps, use_adalora, freeze_encoder, fp16, use_8bit,
            output_dir, num_train_epochs, learning_rate, warmup_steps,
            per_device_train_batch_size, per_device_eval_batch_size,
            gradient_accumulation_steps, logging_steps, eval_steps, save_steps,
            num_workers, save_total_limit,
            resume_from_checkpoint, local_files_only, use_compile, push_to_hub, hub_model_id,
            gpus, save_command_script_flag
        ]
        
        # è®¾ç½®å¼€å§‹æŒ‰é’®çš„ç‚¹å‡»äº‹ä»¶
        start_btn.click(
            fn=start_training,
            inputs=all_input_components,
            outputs=[output_log, command_preview,script_output],
            show_progress=True
        )
        
        # è®¾ç½®åœæ­¢æŒ‰é’®çš„ç‚¹å‡»äº‹ä»¶
        stop_btn.click(
            fn=stop_training,
            outputs=[output_log, command_preview,script_output]
        )
        
        # æ·»åŠ æ—¥å¿—æŸ¥çœ‹æŒ‰é’®
        gr.Markdown("### æ—¥å¿—æŸ¥çœ‹")
        with gr.Row():
            log_view_btn = gr.Button("æŸ¥çœ‹å®Œæ•´æ—¥å¿—")
            log_content = gr.Textbox(label="å®Œæ•´æ—¥å¿—å†…å®¹", lines=10, interactive=False)
        
        log_view_btn.click(
            fn=get_log_content,
            outputs=log_content
        )

    # ======================= æ­¥éª¤3: æ¨¡å‹åˆå¹¶ =======================
    with gr.Tab("æ­¥éª¤3: æ¨¡å‹åˆå¹¶", id="model_merge"):
        gr.Markdown("### ğŸ› ï¸ LoRA æ¨¡å‹åˆå¹¶")
        gr.Markdown("å°†LoRAé€‚é…å™¨åˆå¹¶åˆ°åŸºç¡€æ¨¡å‹ä¸­ï¼Œç”Ÿæˆå¯ç›´æ¥ä½¿ç”¨çš„å®Œæ•´æ¨¡å‹")
        
        with gr.Row():
            with gr.Column():
                lora_model = gr.Textbox(
                    label="LoRA æ¨¡å‹è·¯å¾„", 
                    value="./whisper_output/"
                )
                output_dir = gr.Textbox(
                    label="è¾“å‡ºç›®å½•", 
                    value="./whisper_merged_models/"
                )
                local_files_only_merge = gr.Checkbox(
                    label="ä»…ä½¿ç”¨æœ¬åœ°æ–‡ä»¶", 
                    value=True
                )
                merge_btn = gr.Button("å¼€å§‹åˆå¹¶", variant="primary")
                
            with gr.Column():
                merge_output = gr.Textbox(
                    label="åˆå¹¶ç»“æœ", 
                    lines=8, 
                    interactive=False
                )
        
        merge_btn.click(
            fn=merge_models,
            inputs=[lora_model, output_dir, local_files_only_merge],
            outputs=merge_output
        )
        
        gr.Markdown("### ä½¿ç”¨è¯´æ˜")
        gr.Markdown("""
        1. **LoRAæ¨¡å‹è·¯å¾„**ï¼šè¾“å…¥å¾®è°ƒåçš„æ¨¡å‹ä¿å­˜ç›®å½•è·¯å¾„
        2. **è¾“å‡ºç›®å½•**ï¼šæŒ‡å®šåˆå¹¶åæ¨¡å‹çš„ä¿å­˜ä½ç½®
        3. **ä»…ä½¿ç”¨æœ¬åœ°æ–‡ä»¶**ï¼šå‹¾é€‰åå°†ä¸ä¼šå°è¯•ä»HuggingFace Hubä¸‹è½½æ¨¡å‹
        4. ç‚¹å‡»"å¼€å§‹åˆå¹¶"æŒ‰é’®æ‰§è¡Œåˆå¹¶æ“ä½œ
        5. åˆå¹¶åçš„æ¨¡å‹å°†ä¿å­˜åœ¨æŒ‡å®šè¾“å‡ºç›®å½•ä¸­
        """)

    # ======================= æ­¥éª¤4: æ¨¡å‹ä½¿ç”¨ =======================
    with gr.Tab("æ­¥éª¤4: æ¨¡å‹ä½¿ç”¨", id="model_usage"):
        gr.Markdown("### ğŸ§ è¯­éŸ³è¯†åˆ«ä¸ç¿»è¯‘")
        gr.Markdown("ä½¿ç”¨Whisperæ¨¡å‹è¿›è¡Œè¯­éŸ³è¯†åˆ«æˆ–ç¿»è¯‘")
        
        with gr.Row():
            with gr.Column(scale=1):
                gr.Markdown("#### æ¨¡å‹è®¾ç½®")
                with gr.Group():
                    model_type = gr.Radio(
                        label="æ¨¡å‹ç±»å‹",
                        choices=["åœ¨çº¿æ¨¡å‹", "æœ¬åœ°æ¨¡å‹"],
                        value="åœ¨çº¿æ¨¡å‹"
                    )
                    model_choice = gr.Dropdown(
                        label="é€‰æ‹©åœ¨çº¿æ¨¡å‹", 
                        choices=MODEL_OPTIONS, 
                        value="large-v3",
                        visible=True
                    )
                    custom_model_path = gr.Textbox(
                        label="æœ¬åœ°æ¨¡å‹è·¯å¾„",
                        placeholder="ä¾‹å¦‚: /path/to/your/model",
                        visible=False
                    )
                    download_root_input = gr.Textbox(
                        label="æ¨¡å‹ä¸‹è½½è·¯å¾„ (ä»…åœ¨çº¿æ¨¡å‹)",
                        placeholder="ç•™ç©ºåˆ™é»˜è®¤å½“å‰å·¥ä½œç›®å½•",
                        value="/Whisper-Finetune/whisper-large-v3-turbo",
                        visible=True
                    )
                
                gr.Markdown("#### ä»»åŠ¡è®¾ç½®")
                task_choice = gr.Radio(
                    label="ä»»åŠ¡ç±»å‹",
                    choices=["transcribe", "translate"],
                    value="transcribe"
                )
                
                language_choice = gr.Dropdown(
                    label="è¯­è¨€é€‰æ‹© (ä»…ç”¨äºè¯­éŸ³è¯†åˆ«)",
                    choices=language_options,
                    value="è‡ªåŠ¨æ£€æµ‹",
                    visible=True
                )
                
                file_input = gr.File(
                    label="ä¸Šä¼ éŸ³é¢‘/è§†é¢‘æ–‡ä»¶", 
                    file_types=["audio", "video"]
                )
                submit_btn = gr.Button("å¼€å§‹è½¬å½•", variant="primary")
            
            with gr.Column(scale=1):
                gr.Markdown("#### è¯†åˆ«ç»“æœ")
                output_text = gr.Textbox(
                    label="è¯†åˆ«/ç¿»è¯‘ç»“æœ", 
                    lines=8, 
                    interactive=True
                )
                detected_lang = gr.Textbox(
                    label="æ£€æµ‹åˆ°çš„è¯­è¨€", 
                    interactive=False
                )
                audio_preview = gr.Audio(
                    label="éŸ³é¢‘é¢„è§ˆ", 
                    interactive=False, 
                    visible=False
                )
                
                # éšè—çš„æ–‡æœ¬æ¡†ç”¨äºå­˜å‚¨éŸ³é¢‘æ–‡ä»¶è·¯å¾„
                audio_file_path = gr.Textbox(
                    label="éŸ³é¢‘æ–‡ä»¶è·¯å¾„",
                    visible=False,
                    interactive=False
                )
                
                gr.Markdown("#### ä¿å­˜ç»“æœ")
                dataset_output_dir = gr.Textbox(
                    label="æ•°æ®é›†è¾“å‡ºç›®å½•",
                    value="whisper_dataset"
                )
                save_btn = gr.Button("ä¿å­˜å½“å‰è½¬å½•ç»“æœ", variant="secondary")
                save_result = gr.Textbox(
                    label="ä¿å­˜çŠ¶æ€", 
                    interactive=False
                )
        
        # äº‹ä»¶å¤„ç†
        task_choice.change(
            fn=update_language_visibility,
            inputs=task_choice,
            outputs=language_choice
        )
        
        model_type.change(
            fn=update_model_interface,
            inputs=model_type,
            outputs=[model_choice, custom_model_path, download_root_input]
        )
        
        def process_and_update_audio(file, model_name, task, language, custom_model_path, download_root, model_type):
            """å¤„ç†æ–‡ä»¶å¹¶åŒæ—¶æ›´æ–°éŸ³é¢‘é¢„è§ˆå’Œæ–‡ä»¶è·¯å¾„"""
            text, detected_lang, lang_code, file_path = process_file(file, model_name, task, language, custom_model_path, download_root, model_type)
            return text, detected_lang, lang_code, file_path, file_path  # æœ€åä¸€ä¸ªç”¨äºaudio_preview
        
        submit_btn.click(
            fn=process_and_update_audio,
            inputs=[file_input, model_choice, task_choice, language_choice, custom_model_path, download_root_input, model_type],
            outputs=[output_text, detected_lang, gr.Textbox(visible=False), audio_file_path, audio_preview]
        )
        
        save_btn.click(
            fn=save_dataset_entry,
            inputs=[output_text, audio_file_path, dataset_output_dir],
            outputs=save_result
        )

# åˆ›å»ºæ—¥å¿—ç›®å½•
os.makedirs("training_logs", exist_ok=True)

# ç¡®ä¿ç¼“å­˜ç›®å½•å­˜åœ¨
cache_dir = os.environ.get('GRADIO_CACHE_DIR')
if cache_dir and not os.path.exists(cache_dir):
    os.makedirs(cache_dir, exist_ok=True)

if __name__ == "__main__":
    print(f"ä¸´æ—¶ç›®å½•: {temp_dir}")
    print(f"æ¨¡å‹å°†ä¸‹è½½åˆ°: {os.getcwd()} (é»˜è®¤)")
    
    demo.launch(
        server_name="0.0.0.0",
        server_port=8080,
        share=False,
        show_api=False,
        allowed_paths=["/root/sj-fs"]
    )
